{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カーネル主成分分析を使った非線形写像\n",
    "- 機械学習の多くのアルゴリズムは、入力データの線形分離性の前提を設けている\n",
    "- ここまで取り上げてきた他のアルゴリズムは、線形分離性が完全で無いのはノイズのためであることを前提としている。\n",
    "- ここではカーネルかしたカーネルPCAを取り扱う\n",
    "- カーネルPCAを使って、線形分離できないデータを変換し、線形分類器に適した新しい低次元の部分空間へ射影する方法を学ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.1 カーネル関数とカーネルトリック\n",
    "- 非線形問題を解くには、より高い次元の新しい特徴空間へ射影し、そこで線形分離可能な状態にする。\n",
    "- 高い次元へ変換するために射影関数$\\phi$を定義する。\n",
    "$$\\phi : \\mathbb{R}^{d}　→ \\mathbb{R}^{k} \\, (k>>d)$$\n",
    "- $\\phi$は、元のd次元のデータセットを、より高いk次元の特徴空間に写像するために、元の特徴量の非線形的な組み合わせを作成する。\n",
    "- 例えば、$\\vec{x}$をd個の特徴量からなる列ベクトルとし、２次元(d=2)の特徴ベクトル$\\vec{x} \\in \\mathbb{R}^{d}$があるとすると、3次元空間に以下の様に写像する。\n",
    "$$\\vec{x} = [x_{1},x_{2}]^{T}$$\n",
    "$$↓\\phi$$\n",
    "$$\\vec{z}=[x^{2}_{1},\\sqrt{2x_{1}x_{2}},x^{2}_{2}]$$\n",
    "- カーネルPCAを使用することで、データをより高次元の空間に変換する非線形写像を実行する。\n",
    "- この高次元空間に対して標準のPCAを適用し、より低次元の空間へデータを再び射影し、サンプルを線形分類器に分離できるようにする。\n",
    "- その際には、入力空間においてデータの密度によりサンプルを分離できることが前提となるが、この方法では計算コストが大きすぎる。\n",
    "- カーネルトリックにより、高次元空間に写像することなる、元の特徴空間において２つの高次元の特徴ベクトルの類似度を計算できる。\n",
    "- PCAでは共分散行列を利用した。\n",
    "$$\\sum = \\frac{1}{n} \\sum^{n}_{i=1} \\vec{x}^{(i)} \\vec{x}^{(i)T}$$\n",
    "- この手法は一般化されており、元の特徴空間でのサンプル間の内積を、$\\phi$を使って非線形の特徴量の組み合わせに置き換えることができる。\n",
    "$$\\sum = \\frac{1}{n} \\sum^{n}_{i=1}\\phi(\\vec{x}^{(i)}) \\phi(\\vec{x}^{(i)})^{T}$$\n",
    "- この共分散行列から固有ベクトル（主成分）を取り出すには、以下の方程式を解く必要がある。\n",
    "$$\\sum \\vec{\\nu} =\\lambda\\vec{nu} $$\n",
    "$$\\frac{1}{n} \\sum^{n}_{i=1}\\phi(\\vec{x}^{(i)}) \\phi(\\vec{x}^{(i)})^{T} \\vec{nu} = \\lambda \\vec{\\nu}$$\n",
    "$$\\vec{\\nu} = \\frac{1}{n \\lambda}\\sum^{n}_{i=1} \\phi(\\vec{x}^{(i)}) \\phi(\\vec{x}^{(i)})^{T}\\vec{\\nu} = \\frac{1}{n}\\sum^{n}_{i=1} \\vec{a}^{(i)} \\phi(\\vec{x}^{(i)})$$\n",
    "- ここで$\\lambda$と$\\vec{\\nu}$は共分散行列$\\sum$の固有値と固有ベクトルである。\n",
    "- $\\vec{a}$を取得するには、カーネル（類似度）行列$\\vec{K}$の固有ベクトルを抽出すれば良い\n",
    "$$\\sum = \\frac{1}{n}\\sum^{n}_{i=1} \\phi(\\vec{x}^{(i)}) \\phi(\\vec{x}^{(i)})^{T} = \\frac{1}{n} \\phi(\\vec{X})^{T} \\phi(\\vec{X})$$\n",
    "- この場合の$\\phi(\\vec{X})$はn×k行列である\n",
    "- 固有ベクトル方程式は以下のように記述できる\n",
    "$$\\vec{\\nu} = \\frac{1}{n} \\sum^{n}_{i=1} \\vec{a}^{(i)} \\phi(\\vec{x}^{(i)}) = \\lambda \\phi(\\vec{X})^{T} \\vec{a}$$\n",
    "- $\\sum \\vec{\\nu} = \\lambda \\vec{\\nu}$であることを利用する。以下計算省略\n",
    "$$\\vec{K} = \\phi(\\vec{X}) \\phi(\\vec{X})^{T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- カーネルトリックを利用することによって、サンプル$\\vec{x}$の関数$\\phi$同士の内積の計算をカーネル関数$\\vec{K}$により回避する。\n",
    "- 固有ベクトルを明示的に計算数必要がなくなる\n",
    "$$k(\\vec{x}^{(i)},\\vec{x}^{(j)}) = \\phi(\\vec{x}^{(i)})^{T}\\phi(\\vec{x}^{(j)})$$\n",
    "- カーネルPCAのあとに取得するのは、それぞれの成分にすでに射影されているサンプルである。\n",
    "- 標準のPCAと異なり、変換行列は生成しない。\n",
    "- 基本的にカーネル関数については、２つのベクトル間の内積、つまり類似度の目安を計算する関数とみなすことができる。\n",
    "- 多項式カーネル。$\\theta$は閾値、Pはユーザが指定しなければいけない指数\n",
    "$$k(\\vec{x}^{(i)},\\vec{x}^{(j)}) = (\\vec{x}^{(i)T} \\vec{x}^{(j)} + \\theta)^{P}$$\n",
    "- 双曲線正接（S字）カーネル\n",
    "$$k(\\vec{x}^{(i)},\\vec{x}^{(j)}) = tanh(\\eta \\vec{x}^{(i)T} \\vec{x}^{(j)} + \\theta)$$\n",
    "- 動径基底関数（RBF）またはガウスカーネル。\n",
    "$$k(\\vec{x}^{(i)},\\vec{x}^{(j)}) = exp\\left( - \\frac{\\| \\vec{x}^{(i)}-\\vec{x}^{(j)} \\|^{2}}{2\\sigma^{2}}  \\right)$$\n",
    "$$k(\\vec{x}^{(i)},\\vec{x}^{(j)}) = exp\\left( - \\gamma \\| \\vec{x}^{(i)}-\\vec{x}^{(j)} \\|^{2} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RBFカーネルPCAの実装は、以下の３ステップにまとめることができる\n",
    "\n",
    "１．カーネル（類似度）行列$\\vec{K}$を計算し、そこで以下の計算を行う必要がある。以下の計算をサンプルペア毎に行う。\n",
    "$$k(\\vec{x}^{(i)},\\vec{x}^{(j)}) = exp\\left( - \\gamma \\| \\vec{x}^{(i)}-\\vec{x}^{(j)} \\|^{2} \\right)$$\n",
    "$$\\vec{K} = \\begin{bmatrix} k(\\vec{x}^{(1)},\\vec{x}^{(1)}) & k(\\vec{x}^{(1)},\\vec{x}^{(2)}) & \\ldots  & k(\\vec{x}^{(1)},\\vec{x}^{(n)}) \\\\ k(\\vec{x}^{(2)},\\vec{x}^{(1)}) & k(\\vec{x}^{(2)},\\vec{x}^{(2)}) & \\ldots  & k(\\vec{x}^{(2)},\\vec{x}^{(n)}) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ k(\\vec{x}^{(n)},\\vec{x}^{(1)}) & k(\\vec{x}^{(n)},\\vec{x}^{(2)}) & \\ldots  & k(\\vec{x}^{(n)},\\vec{x}^{(n)}) \\end{bmatrix}$$\n",
    "- 例えば、データセットにトレーニングサンプルが100個含まれている場合ペアごとの類似度からなる対象カーネルは行列は100×100次元になる\n",
    "\n",
    "２．カーネル行列$\\vec{K}$の中心化を行う\n",
    "$$\\vec{K}^{''} = \\vec{K} - \\vec{l_{n}}\\vec{K}-\\vec{K}\\vec{l_{n}} + \\vec{l_{n}}\\vec{K}\\vec{l_{n}}$$\n",
    "- $\\vec{l}_{n}$はすべての値が$\\frac{1}{n}$のn×n次元の行列である。（次元の数はカーネル関数と同じ）\n",
    "\n",
    "３．対応する固有値に基づき、中心化されたカーネル行列のk個のベクトルを収集する。この場合、固有値は大きい順にランク付けされている。標準のPCAとは対処的に、固有ベクトルは主成分軸ではなく、それらの軸に射影されるサンプルである。\n",
    "\n",
    "- これまでは標準化されたデータを使うことが前提となっていたが、新しい特徴空間を明示的に計算せず、新しい特徴空間でも中心が0であることを保証できないから中心化する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.2 pythonでカーネル主成分分析を実装する。\n",
    "- RBFカーネルPCAをpythonで実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist,squareform #pdistは距離関数\n",
    "from scipy import exp\n",
    "from scipy.linalg import eigh\n",
    "import numpy as np\n",
    "\n",
    "def rbf_kernel_pca(X,gamma,n_components):\n",
    "    \"\"\"RBFカーネルPCAの実装\n",
    "    \n",
    "    パラメータ\n",
    "    ------------\n",
    "    X:{Numpy array}, shape = [n_samples,n_features]\n",
    "    \n",
    "    gamma: float\n",
    "        RBFカーネルのチューニングパラメータ\n",
    "        \n",
    "    n_components: int\n",
    "        返される主成分の個数\n",
    "        \n",
    "    戻り値\n",
    "    ------------\n",
    "    X_pc:{Numpy array},shape=[n_samples,n_features]\n",
    "        射影されたデータセット\n",
    "    \"\"\"\n",
    "    #M×N次元のデータセットでペア毎に平方ユーグリッド距離を計算\n",
    "    sq_dists = pdist(X,'sqeuclidean')\n",
    "    \n",
    "    #ペアごとの距離を正方行列に変換\n",
    "    mat_sq_dists = squareform(sq_dists)\n",
    "    \n",
    "    #対象カーネル行列を計算\n",
    "    K = exp(-gamma*mat_sq_dist)\n",
    "    \n",
    "    #カーネル行列を中心化\n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N,N)) / float(N)\n",
    "    K = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)\n",
    "    \n",
    "    #中心化されたカーネル行列から固有値を取得\n",
    "    #numpy.eighはそれらをソート順に返す\n",
    "    eigvals,eigvecs = eigh(K)\n",
    "    \n",
    "    #上位K個の固有ベクトル（射影されたサンプル）を収集\n",
    "    X_Ppc = np.column_stack((eigvecs[:,-i] for i in range(1,n_components+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
