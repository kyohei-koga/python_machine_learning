{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの評価とハイパーパラメータのチューニングのベストプラクティス\n",
    "- アルゴリズムをチューニングし、モデルの性能を評価する\n",
    "- モデルの性能の偏りのない推定量の算出\n",
    "- 機械学習のアルゴリズムに共通する問題の診断\n",
    "- 機械学習のモデルのチューニング\n",
    "- さまざまな性能指標に基づく予測モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1パイプラインによるワークフローの効率化\n",
    "- scikit learnのPipelineクラスは非常に便利である\n",
    "- このクラスを利用すれば任意の個数の変換ステップを含んだモデルを学習し、それをお応用して新しいデータを予測できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1.1 Breast Cancer Wisconcinデータセットを読み込む\n",
    "- このデータセットには、悪性腫瘍細胞と良性腫瘍細胞の569のサンプルが含まれている。\n",
    "- 特徴量としては、細胞核のデジタル画像から算出された30個の実数値が含まれてる。\n",
    "- 腫瘍が良性か悪性かを予測するモデルの構築に利用できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#データセットを読み込む\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#特徴量をX、ターゲットをyに格納\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "X = df.loc[:,2:].values\n",
    "y = df.loc[:,1].values\n",
    "#クラスラベルの文字列表現を整数に変換する\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "#エンコードの確認\n",
    "print le.transform(['M','B'])\n",
    "#エンコードの確認２\n",
    "print le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#トレーニングデータセットとテストデータセットに分割する\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1.2 パイプラインで変換器と推定器を結合する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#連結する処理としてスケーリング、主成分分析、ロジスティック回帰を指定\n",
    "pipe_lr = Pipeline([('scl',StandardScaler()),('pca',PCA(n_components=2)),('clf',LogisticRegression(random_state=1))])\n",
    "pipe_lr.fit(X_train,y_train)\n",
    "print('Test Accuracy: %.3f') %pipe_lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- パイプラインの中間ステップである変換器の個数には制限が無い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 K分割交差検証を使ったモデルの性能の評価\n",
    "- 機械学習モデルの構築において重要なステップの１つは、モデルにとって未知のデータを使って性能を評価することである。\n",
    "- バイアスとバリアンスの適度なバランスをとるには、モデルを入念に評価する必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2.1 ホールドアウト法\n",
    "- ホールドアウト法はモデルの汎化性能を評価するために使用される一般的アプローチである。\n",
    "- 一般に機械学習を応用するには、未知のデータに対する予測性能をさらに向上させるために、様々なパラメータ設定のチューニングや比較を行うことも重要である。このプロセスはモデル選択と呼ばれる。\n",
    "- モデル選択に同じテストデータセットを繰り返し利用した場合、それはトレーニングデータセットの一部となる。このため、モデルが過学習に陥る可能性が高くなる。\n",
    "- モデル選択にホールドアウト法を使用する場合、より効果的な方法は、データをトレーニングデータセット、検証データセット、テストデータセットの３つに分割することである。\n",
    "- トレーニングデータセットは様々なモデルの学習に使用される。\n",
    "- 検証データセットでの性能は、モデル選択に使用される。\n",
    "- トレーニングステップとモデル選択ステップで未知のテストデータセットを使用することにより、利点を享受できる。\n",
    "- 利点とは、新しいデータを汎化する能力を評価についてモデルを評価するときにバイアスが低くなることである。\n",
    "- ホールドアウト法には問題点が１つある。元のトレーニングデータセットをトレーニングサブセットと検証サブセットにどのように分割するかによって、性能の評価に影響が及ぶことである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2.1 k分割交差検証\n",
    "- トレーニングデータセットのk個のサブセットに対してホールドアウト法をｋ回繰り返す。\n",
    "- 非復元抽出を用いて、トレーニングデータセットをランダムにk個に分割する。そのうちのk-1個をモデルのトレーニングに使用し、１個をテストに使用する。この手順をk回繰り返すことで、k個のモデルと性能評価を取得する。\n",
    "- 個々のサブセットに基づいてモデルの平均性能を計算する。\n",
    "- ホールドアウト法と比べてトレーニングデータの再分割に敏感でない性能評価を取得できる。\n",
    "- 一般にk分割交差検証はモデルのチューニングに使用される。ハイパーパラメータの最適値を見つけるために行われる。\n",
    "- 満足の行くハイパーパラメータ値が見つかったら、トレーニングデータセット全体でモデルを再トレーニングし、トレーニングデータセットからは独立したテストデータセットを使って最終的な性能評価を得ることができる。\n",
    "- 非復元抽出法のため、トレーニングデータセットとテストデータセットのペアが与えられたときに、各サンプル点はその中に１回しか現れない。このため、ホールドアウト法よりもバリアンスの低い性能評価が得られる事が利点である。\n",
    "- k分割交差検証で標準的に用いられるkの値は10であり、ほとんどの場合は妥当な選択である。\n",
    "- 比較的小さなトレーニングデータセットを扱っている場合は、分割数を増やすと良いかもしれない。\n",
    "- kの値を増やすと汎化性能の評価に対するバイアスが低くなる。\n",
    "- k分割交差検証を改善したものが、層化k分割交差検証である。クラスの比率が均等でないケースでは、評価のバイアスとバリアンスが改善される。\n",
    "- 層化交差検証では、各サブセットでのクラスの比率が維持される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1, Class dist.: [256 153], Acc : 0.891\n",
      "Fold : 2, Class dist.: [256 153], Acc : 0.978\n",
      "Fold : 3, Class dist.: [256 153], Acc : 0.978\n",
      "Fold : 4, Class dist.: [256 153], Acc : 0.913\n",
      "Fold : 5, Class dist.: [256 153], Acc : 0.935\n",
      "Fold : 6, Class dist.: [257 153], Acc : 0.978\n",
      "Fold : 7, Class dist.: [257 153], Acc : 0.933\n",
      "Fold : 8, Class dist.: [257 153], Acc : 0.956\n",
      "Fold : 9, Class dist.: [257 153], Acc : 0.978\n",
      "Fold : 10, Class dist.: [257 153], Acc : 0.956\n",
      "CV accuracy : 0.950 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold #イテレータオブジェクト\n",
    "#分割元データ、分割数、乱数生成器の状態を指定し、層化k分割交差検証イテレータを表すStratifiedKFoldクラスのインスタンス化\n",
    "kfold = StratifiedKFold(y=y_train,n_folds=10,random_state=1)\n",
    "\n",
    "scores = []\n",
    "#イテレータのインデックスと要素をループ処理\n",
    "#  データをモデルに適合\n",
    "#  テストデータの正解率を算出\n",
    "#  リストに正解率を追加\n",
    "#  分割の番号、0以上の要素数、正解率を出力\n",
    "for k, (train,test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train],y_train[train])\n",
    "    score = pipe_lr.score(X_train[test],y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold : %s, Class dist.: %s, Acc : %.3f') %(k+1,np.bincount(y_train[train]),score)\n",
    "#正解率の平均と標準偏差を出力\n",
    "print('CV accuracy : %.3f +/- %.3f') %(np.mean(scores),np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.89130435  0.97826087  0.97826087  0.91304348  0.93478261  0.97777778\n",
      "  0.93333333  0.95555556  0.97777778  0.95555556]\n",
      "CV accuracy: 0.950 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "#より効率的なプログラミング\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#交差検証のcross_val_score関数でモデルの正解率を算出\n",
    "#推定器estimator,トレーニングデータX,予測値y,分割数cv,CPU数n_jobsを指定\n",
    "scores = cross_val_score(estimator=pipe_lr,X=X_train,y=y_train,cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s') %scores\n",
    "print('CV accuracy: %.3f +/- %.3f') %(np.mean(scores),np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross_val_score関数のアプローチの極めて便利な特徴の１つとして、サブセット毎の評価の計算処理をマシン上の複数のCPUに分散させることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
